<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Peer Review on the stupidest thing...</title>
    <link>http://kbroman.org/blog/tags/peer-review/</link>
    <description>Recent content in Peer Review on the stupidest thing...</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>The text in this work is licensed under CC-BY-4.0, https://creativecommons.org/licenses/by/4.0/legalcode; code licensed under the MIT License</copyright>
    <lastBuildDate>Sun, 09 Feb 2014 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://kbroman.org/blog/tags/peer-review/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>I still don&#39;t like it</title>
      <link>http://kbroman.org/blog/2014/02/09/i-still-dont-like-it/</link>
      <pubDate>Sun, 09 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2014/02/09/i-still-dont-like-it/</guid>
      <description>&lt;p&gt;I got a book in the mail this week, a book I hadn&amp;rsquo;t ordered and would never have ordered. The publisher sent me a complimentary copy, as I&amp;rsquo;d reviewed the book proposal last year. (It&amp;rsquo;s the one where &lt;a href=&#34;http://kbroman.org/blog/2013/03/07/what-a-waste-of-paper/&#34;&gt;the author refused to allow me to have an electronic copy&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;Actually, I soundly trashed the proposal in my review. In the nicest possible way, of course. For example, I said:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;And then there are things that are just plain wrong. For example, &amp;ldquo;We then express our confidence in the H0 with a p-value, which might crudely be considered the probability that the H0 is true.&amp;rdquo; That is not a &lt;em&gt;crude&lt;/em&gt; interpretation of the p-value; that is just &lt;em&gt;wrong&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It seems like if a reviewer says, &amp;ldquo;This particular book should not be adopted,&amp;rdquo; the publisher can interpret that to also mean, &amp;ldquo;and whatever you do, don&amp;rsquo;t send me a copy.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Complaints about the NIH grant review process</title>
      <link>http://kbroman.org/blog/2013/10/02/complaints-about-the-nih-grant-review-process/</link>
      <pubDate>Wed, 02 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2013/10/02/complaints-about-the-nih-grant-review-process/</guid>
      <description>

&lt;p&gt;Earlier this week, I met with a collaborator to discuss what to do with our NIH grant proposal, whose &amp;ldquo;A1&amp;rdquo; was &amp;ldquo;unscored&amp;rdquo; (ie, the revised version, and you don&amp;rsquo;t get a third try, received a &amp;ldquo;preliminary score&amp;rdquo; in the lower half and so was not discussed by the review panel and couldn&amp;rsquo;t be funded).&lt;/p&gt;

&lt;p&gt;NIH proposals are typically reviewed by three people and given preliminary scores on five aspects (significance, approach, investigators, environment, innovation) and overall, and the top proposals based on those scores are discussed and scored by the larger panel.&lt;/p&gt;

&lt;p&gt;One of the reviewers gave our proposal an 8 for &amp;ldquo;approach&amp;rdquo; (on a scale of 1-9, with 1 being good and 9 being terrible) with the following review comments:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;4. Approach:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Strengths&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Well described details for mining of [data] and genotyping of [subjects].&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Weaknesses&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There is no power analysis for Aim 2. Without knowing which and how many [phenotypes] will be evaluated it is not possible to estimate the statistical power.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Valid comments, but is that really all the reviewer had to say? What about Aims 1 and 3, or the other aspects of Aim 2? &lt;em&gt;That is totally fucking inadequate.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Looking at this review again, I was reminded of how much I despise many aspects of the NIH review process. So it&amp;rsquo;s led me, finally, to write down some of the things that annoy me.&lt;/p&gt;

&lt;h3 id=&#34;the-scoring-system-is-too-discrete&#34;&gt;The scoring system is too discrete&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve been involved in reviewing NIH grants for 15 years. A bunch of changes were made in about 2009 or so, with a few things for the better (like having the review order of grants based on preliminary score) but many for the worse.&lt;/p&gt;

&lt;p&gt;The worst change was to the scoring system. In the old system, reviewers scored grants on a scale of 1-5, in tenths (1.0, 1.1, 1.2, &amp;hellip;), with 1 being best and 5 being worst. Scores were averaged and multiplied by 100, so the best possible score was 100 and the worst was 500. (And note that the middle value was 300 not 250, a point of confusion for many.)&lt;/p&gt;

&lt;p&gt;In the new system, reviewers score grants on a scale of 1-9, in single digits, with 1 being best and 9 being worst (and 5 being the middle value). Scores are averaged and multiplied by ten, so the best possible score is 10 and the worst is 90.&lt;/p&gt;

&lt;p&gt;When the new scale was introduced, we were given the following handy chart:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://kbroman.files.wordpress.com/2013/10/nih_score_chart.png&#34; alt=&#34;NIH 9-point score chart&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As I understand it, there were two main reasons for revising the scoring system:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Fix the &amp;ldquo;grade inflation&amp;rdquo; problem (too many good scores)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Reviewers can&amp;rsquo;t score grants with 0.1 precision.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But as a fix for the grade inflation problem, revising the scoring system could only be a temporary solution. And as I understand it, the problem is now worse than ever.&lt;/p&gt;

&lt;p&gt;The big problem with the new scoring system is that reviewers have just 9 choices of scores, whereas before they had 41. Yes, a reviewer can&amp;rsquo;t really discriminate 1.3 from 1.4. &lt;strong&gt;But if you have 25 imprecise measure instruments, would it be better to&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;average and then round&lt;/em&gt;, or&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;round and then average&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It&amp;rsquo;s obviously better to &lt;em&gt;average and then round&lt;/em&gt;, but the new scoring system &lt;em&gt;rounds and then averages&lt;/em&gt;. (&lt;a href=&#34;http://churchill.jax.org/about/churchill.shtml&#34;&gt;Gary Churchill&lt;/a&gt; pointed this out to me.)&lt;/p&gt;

&lt;p&gt;This leads to the frequent statements like, &amp;ldquo;I&amp;rsquo;d put this somewhere between a 1 and a 2.&amp;rdquo; And with line (or &amp;ldquo;band&amp;rdquo;) between funded and not funded being well above 20, it seems like, in many cases, &lt;em&gt;whether a grant is funded has to do with the proportion of reviewers that give it a 1&lt;/em&gt; rather than a 2.&lt;/p&gt;

&lt;h3 id=&#34;the-bullet-point-based-reviews-lead-to-superficial-and-incomplete-comments&#34;&gt;The bullet-point-based reviews lead to superficial and incomplete comments&lt;/h3&gt;

&lt;p&gt;It used to be that the written reviews of grant proposals were much like reviews of journal articles: for each aspect of a proposal (significance, approach, etc.), we&amp;rsquo;d write a few paragraphs, in some cases a full page. Such reviews were hard to write, were often long, and sometimes didn&amp;rsquo;t do a good job of making clear what were the really important issues and what were the less important ones.&lt;/p&gt;

&lt;p&gt;With the big review change in 2009, reviewers were asked to write bullet points for &amp;ldquo;Strengths&amp;rdquo; and &amp;ldquo;Weaknesses.&amp;rdquo; (And in a Microsoft Word template!)&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a lot easier to write a few bullet points than to construct coherent prose, but the bullet points that reviewers produce are generally shallow and incomplete. In some cases, a reviewer&amp;rsquo;s thinking about a proposal may be left in a shallow and incomplete state.&lt;/p&gt;

&lt;p&gt;The review at the top of this post is the best (or really &lt;em&gt;worst&lt;/em&gt;) instance of this problem.&lt;/p&gt;

&lt;h3 id=&#34;don-t-drop-the-proposal-summary-from-the-beginning-of-the-discussion&#34;&gt;Don&amp;rsquo;t drop the proposal summary from the beginning of the discussion&lt;/h3&gt;

&lt;p&gt;In the old days, the discussion of a proposal would begin with the primary reviewer giving a brief summary: what are the investigators proposing to do? This is critical, as only 3 of the 25 or so people on the panel will have read the proposal.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know if they&amp;rsquo;re still doing this, but with the other changes to the review process, we were asked to skip the summary of proposal and just discuss the significance of the work. But how on earth can you talk about the significance of the work without some mention of what the work actually is?&lt;/p&gt;

&lt;h3 id=&#34;the-electronic-grant-format-is-often-not-human-readable&#34;&gt;The electronic grant format is often not human readable.&lt;/h3&gt;

&lt;p&gt;When I first reviewed NIH grant proposals, we each got a copy-paper-sized box with all of the proposals (and when proposals were triaged, all 25 reviewers would simultaneously throw the proposal into a big pile). It was great to move to electronic versions of grants (initially scanned, then fully electronic), but the electronic versions of proposals are not constructed in a way that has a human reader in mind.&lt;/p&gt;

&lt;p&gt;The front page of grants used to be quite clear and informative, but now all of the form-generated pages are a design mess. For example, the pages listing the key personnel and their institutions are really hard to parse.&lt;/p&gt;

&lt;p&gt;Also, there are loads of useless pages describing what documents were included. Couldn&amp;rsquo;t the reviewers get a version without all of that crap?&lt;/p&gt;

&lt;p&gt;Finally, the PDF bookmarks are often off by a page. If you want to go to the biosketches, you need to click the biosketch bookmark and then page down one.&lt;/p&gt;

&lt;p&gt;These things aren&amp;rsquo;t &lt;em&gt;that&lt;/em&gt; big of a deal, but they&amp;rsquo;re a constant annoyance, and they should be easy to fix.&lt;/p&gt;

&lt;p&gt;Tony Scarpa, the former director of the &lt;a href=&#34;http://public.csr.nih.gov/Pages/default.aspx&#34;&gt;NIH Center for Scientific Review (CSR)&lt;/a&gt; who was responsible for the big change in the NIH review system, once visited U Wisconsin, and I asked him about whether these electronic proposals could be improved, and he said, &amp;ldquo;Oh, that&amp;rsquo;s not us; that&amp;rsquo;s grants.gov.&amp;rdquo; So I asked who I should talk to about the issue, and he said, &amp;ldquo;Call your Congressman.&amp;rdquo;&lt;/p&gt;

&lt;h3 id=&#34;there-needs-to-be-some-review-of-reviewers&#34;&gt;There needs to be some review of reviewers&lt;/h3&gt;

&lt;p&gt;One final comment: there needs to be some formal way for reviewers to comment on other reviewers. I think most reviewers are very careful and responsible, but there&amp;rsquo;s often at least one total jerk on a review panel: didn&amp;rsquo;t read the proposal carefully, didn&amp;rsquo;t write a coherent review, didn&amp;rsquo;t pay any attention to what the other reviewers said, gave completely unfair scores.&lt;/p&gt;

&lt;p&gt;There should be some system for other reviewers to say, &amp;ldquo;So-and-so on the panel was a complete jerk and shouldn&amp;rsquo;t be brought back.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Code review</title>
      <link>http://kbroman.org/blog/2013/09/25/code-review/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2013/09/25/code-review/</guid>
      <description>

&lt;p&gt;There was an &lt;a href=&#34;http://www.nature.com/news/mozilla-plan-seeks-to-debug-scientific-code-1.13812&#34;&gt;interesting news item&lt;/a&gt; in Nature on &lt;a href=&#34;http://en.wikipedia.org/wiki/Code_review&#34;&gt;code review&lt;/a&gt;.  It describes a project by some folks at Mozilla to review the code (well, really just 200-line snippets) from 6 selected papers in computational biology.&lt;/p&gt;

&lt;p&gt;There are very brief quotes from &lt;a href=&#34;http://ivory.idyll.org/blog/&#34;&gt;Titus Brown&lt;/a&gt; and &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger Peng&lt;/a&gt;.  I expect that the author of the item, &lt;a href=&#34;http://www.nature.com/nature/about/editors/index.html#ErikaCheckHayden&#34;&gt;Erika Check Hayden&lt;/a&gt;, spoke to Titus and Roger at length but could just include short bits from each, and so what they say probably doesn&amp;rsquo;t fully (or much at all) characterize their view of the issue.&lt;/p&gt;

&lt;p&gt;Titus is quoted as follows, in reference to another scientist who retracted five papers due to an error in his code:&lt;/p&gt;

&lt;blockquote&gt;&#34;That&#39;s the kind of thing that should freak any scientist out.... We don&#39;t have good processes in place to detect that kind of thing in software.&#34;&lt;/blockquote&gt;

&lt;p&gt;Roger is quoted at the end, as follows:&lt;/p&gt;

&lt;blockquote&gt;&#34;One worry I have is that, with reviews like this, scientists will be even more discouraged from publishing their code.... We need to get more code out there, not improve how it looks.&#34;&lt;/blockquote&gt;

&lt;p&gt;I agree with both of them, but my initial reaction, from the beginning of the piece, was closer to Roger&amp;rsquo;s: We often have a heck of time getting any code out of people; if we are too hard on people regarding the quality of their code, they might become even less willing to share.&lt;/p&gt;

&lt;p&gt;On the one hand, we want people to produce good code:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;that works&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;that&amp;rsquo;s readable&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;that&amp;rsquo;s reusable&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And it would be great if, for every bit of code, there was a second programmer who studied it, verified that it was doing the right thing, and offered suggestions for improvement.&lt;/p&gt;

&lt;p&gt;But, on the other hand, it seems really unlikely that journals have the resources to do this. And I worry that a study showing that much scientific software is crap will make people even less willing to share.&lt;/p&gt;

&lt;p&gt;I would like to see the code associated with scientific articles made readily available, during the review process and beyond. But I don&amp;rsquo;t think we (as a scientific community) want to enforce rigorous code review prior to publication.&lt;/p&gt;

&lt;p&gt;Later, on twitter, &lt;a href=&#34;https://twitter.com/ctitusbrown/status/382862626692149248&#34;&gt;Titus took issue&lt;/a&gt; with the &amp;ldquo;not improve how it looks&amp;rdquo; part of what Roger said:&lt;/p&gt;

&lt;blockquote&gt;&#34;.@kwbroman @simplystats @rdpeng Please read &lt;http://en.wikipedia.org/wiki/Code_review&gt; you are deeply, significantly, and completely wrong about code review.&#34;&lt;/blockquote&gt;

&lt;p&gt;Characterizing code review as strictly cosmetic was an unfortunate, gross simplification. (And how code looks &lt;em&gt;is&lt;/em&gt; important.)&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t have enough time this morning to really clean up my thoughts on this issue, and I want to get this out and move on to reading that dissertation that I have to get through by tomorrow. So, let me summarize.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;We want scientific code to be &lt;em&gt;well written&lt;/em&gt;: does what it&amp;rsquo;s intended to do, readable, reusable.&lt;/p&gt;

&lt;p&gt;We want scientific code to be &lt;em&gt;available&lt;/em&gt;. (Otherwise we can&amp;rsquo;t verify that it does what it&amp;rsquo;s intended to do, or reuse it.)&lt;/p&gt;

&lt;p&gt;If we&amp;rsquo;re too hard on people for writing substandard code, we&amp;rsquo;ll discourage the availability. It&amp;rsquo;s an important trade-off.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Knuth: Journal referees should assist authors</title>
      <link>http://kbroman.org/blog/2013/04/08/knuth-journal-referees-should-assist-authors/</link>
      <pubDate>Mon, 08 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2013/04/08/knuth-journal-referees-should-assist-authors/</guid>
      <description>&lt;p&gt;When serving as referee for a journal, who are you working for?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;The editor&lt;/em&gt;: Will the paper add to the journal&amp;rsquo;s prestige?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;The reader&lt;/em&gt;: Is it worth reading?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;The author&lt;/em&gt;: How can it be improved?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;d long thought that the referee&amp;rsquo;s duty was to the journal editors and then to the readers.&lt;/p&gt;

&lt;p&gt;But Donald Knuth&amp;rsquo;s comments on refereeing persuaded me that I should focus primarily on helping the author to improve the manuscript.&lt;/p&gt;

&lt;p&gt;See pages 31-35 (as numbered; actually 33-37 in the pdf) in his &lt;a href=&#34;http://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf&#34;&gt;notes on mathematical writing&lt;/a&gt;. And here&amp;rsquo;s the &lt;a href=&#34;http://www.ifs.tuwien.ac.at/~silvia/research-tips/Knuth.pdf&#34;&gt;missing page on &amp;ldquo;Hints for referees&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Even a terrible manuscript can be published, if the author is sufficiently persistent. Your primary job as referee should be to help the author to make it as good as it can be.&lt;/p&gt;

&lt;p&gt;Almost immediately after I first read Donald Knuth&amp;rsquo;s comments (back in 2002), I received one of the worst manuscripts I&amp;rsquo;ve ever read. It was one of those cases where I really wish the authors were anonymous, because I can&amp;rsquo;t forget who was responsible for it.&lt;/p&gt;

&lt;p&gt;It was hard for me to say, &amp;ldquo;You have no idea what you&amp;rsquo;re doing&amp;rdquo; in a constructive way. (&amp;ldquo;You should abandon this manuscript&amp;rdquo; is not constructive, but it could be good advice. The scientific literature could use a bit more self-censorship.)&lt;/p&gt;

&lt;p&gt;And I&amp;rsquo;ve learned to use the &amp;ldquo;Comments to the editor&amp;rdquo; as my opportunity to vent. (I would pity the poor editor on the other end, but she/he sent the thing to me!) I&amp;rsquo;d give an example of my venting, but I think I&amp;rsquo;ll leave that to another time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What a waste of paper</title>
      <link>http://kbroman.org/blog/2013/03/07/what-a-waste-of-paper/</link>
      <pubDate>Thu, 07 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2013/03/07/what-a-waste-of-paper/</guid>
      <description>&lt;p&gt;A university press asked me to review a book manuscript, and the author &amp;ldquo;has asked that we not use electronic copies.&amp;rdquo; So they&amp;rsquo;re going to send me a hard copy.&lt;/p&gt;

&lt;p&gt;My response: &amp;ldquo;If you only give me a paper copy, I&amp;rsquo;m going to just scan it and toss the paper. That seems like a waste of time (and paper and postage).&amp;rdquo;&lt;/p&gt;

&lt;p&gt;I should probably have said, &amp;ldquo;Then forget it.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Their response included, &amp;ldquo;What you do with it when it arrives I am just going to take a hear-no-evil approach to.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Web-enabled publishing environment</title>
      <link>http://kbroman.org/blog/2012/10/23/web-enabled-publishing-environment/</link>
      <pubDate>Tue, 23 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/10/23/web-enabled-publishing-environment/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.stat.wisc.edu/~karlrohe/&#34;&gt;Karl Rohe&lt;/a&gt; has &lt;a href=&#34;http://magazine.amstat.org/blog/2012/10/01/stats-view-oct12/&#34;&gt;an interesting commentary&lt;/a&gt; in &lt;a href=&#34;http://magazine.amstat.org&#34;&gt;Amstat News&lt;/a&gt; this month, on how our current publishing system is obstructing research progress, and what a better future might look like.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What, no coffee?</title>
      <link>http://kbroman.org/blog/2012/09/28/what-no-coffee/</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/09/28/what-no-coffee/</guid>
      <description>&lt;p&gt;I was at a &lt;a href=&#34;http://www.cidr.jhmi.edu/about/CIDR%20Access%20Committee.pdf&#34;&gt;CIDR Access Committee&lt;/a&gt; meeting in DC a few weeks ago. We review proposals for genotyping or sequencing by the &lt;a href=&#34;http://www.cidr.jhmi.edu&#34;&gt;Center for Inherited Disease Research&lt;/a&gt;, a service funded by several of the NIH institutes.&lt;/p&gt;

&lt;p&gt;We had to buy our own coffee.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s silly to complain. There was a coffee shop across the hall from the meeting room, and the coffee there was suitable.&lt;/p&gt;

&lt;p&gt;But isn&amp;rsquo;t it silly to pay airfare for a dozen people for a 3 hr meeting and then chintz on the snacks?  Apparently it&amp;rsquo;s a &lt;a href=&#34;http://www.hhs.gov/asfr/ogapa/acquisition/appfundspol_att2.html&#34;&gt;new government rule&lt;/a&gt;.  (I&amp;rsquo;d thought the rule was maybe instituted following the &lt;a href=&#34;http://www.nytimes.com/2012/04/04/us/politics/gsa-las-vegas-trip-is-the-talk-of-washington.html&#34;&gt;GSA&amp;rsquo;s Las Vegas party&lt;/a&gt;, but it predates that.)&lt;/p&gt;

&lt;p&gt;Without coffee, &lt;a href=&#34;http://www.freestatebrewing.com&#34;&gt;grant reviewing does not seem to go as well&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Positive comments on peer review</title>
      <link>http://kbroman.org/blog/2012/04/27/positive-comments-on-peer-review/</link>
      <pubDate>Fri, 27 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/04/27/positive-comments-on-peer-review/</guid>
      <description>&lt;p&gt;We all complain about peer review, particularly when &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/publications/inversion.pdf&#34;&gt;our best work&lt;/a&gt; is rejected by every journal from Nature Genetics down to &lt;a href=&#34;http://www.biomedcentral.com/bmcgenet&#34;&gt;that journal that will publish anything&lt;/a&gt;, so that it finally appears in &lt;a href=&#34;http://projecteuclid.org/euclid.lnms/1215091126&#34;&gt;a volume&lt;/a&gt; to honor &lt;a href=&#34;http://www.stat.berkeley.edu/~terry/&#34;&gt;some guy&lt;/a&gt; that &lt;a href=&#34;http://kbroman.files.wordpress.com/2012/04/terry2.jpg&#34;&gt;only he will read&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, sometimes &lt;a href=&#34;http://medicine.yale.edu/ysph/people/hongyu_zhao.profile&#34;&gt;an anonymous reviewer&lt;/a&gt; will identify an important flaw in &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/publications/interfer.pdf&#34;&gt;a paper&lt;/a&gt; that you can fix before it&amp;rsquo;s published, thus saving you from potential public embarrassment.&lt;/p&gt;

&lt;p&gt;That happened to me again today.  I finally got the reviews back for &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/publications/phyloqtl_combined.pdf&#34;&gt;a paper&lt;/a&gt;, eight weeks after it was submitted.  I had become a bit impatient, but one of the reviewers identified a hole in our theory section, which we can now fix before publication (I think &lt;a href=&#34;http://www.stat.wisc.edu/~ane/&#34;&gt;we&lt;/a&gt; figured it out this afternoon), thus avoiding public embarrassment, except for the fact that I&amp;rsquo;m currently pointing it out publicly.&lt;/p&gt;

&lt;p&gt;Complaints about the peer review process are not unlike a common complaint about statisticians: that we are a barrier to scientists publishing what they know to be true.  That is sometimes the case, but at other times, both reviewers and statisticians can help you to avoid embarrassing yourself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I just refused an Elsevier review</title>
      <link>http://kbroman.org/blog/2012/02/10/i-just-refused-an-elsevier-review/</link>
      <pubDate>Fri, 10 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/02/10/i-just-refused-an-elsevier-review/</guid>
      <description>&lt;p&gt;This afternoon I refused a request from the American Journal of Human Genetics to review a paper, though the abstract was extremely interesting.  AJHG is published by Elsevier, and I&amp;rsquo;d signed the declaration at &lt;a href=&#34;http://thecostofknowledge.com&#34;&gt;http://thecostofknowledge.com&lt;/a&gt; to not publish or review for Elsevier journals.  If only AJHG were still with the University of Chicago Press&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.michaeleisen.org/blog/?p=890&#34;&gt;Michael Eisen recently wrote&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
The boycott isn&#39;t perfect. I wish they hadn&#39;t focused exclusively on Elsevier – they are hardly the only bad actors in the field. And it&#39;s crucial that the focus be on papers. Nobody views turning down invitations to review to be a big sacrifice – and publishers will just find someone else. Same thing with editors. But papers are their lifeblood.
&lt;/blockquote&gt;

&lt;p&gt;I agree with him.  It&amp;rsquo;s easy to turn down a review. (I do so several times a week.)&lt;/p&gt;

&lt;p&gt;And so I was feeling quite unsure about turning down the review, but also unsure about breaking the pledge regarding Elsevier.  Nevertheless, I came down on the side of the pledge, and responded to AJHG with the following:&lt;/p&gt;

&lt;blockquote&gt;
It sounds like an interesting paper, but...

I recently signed a public declaration to not publish or review for
Elsevier journals (&lt;a href=&#34;http://thecostofknowledge.com&#34;&gt;http://thecostofknowledge.com&lt;/a&gt;).  I noticed at the time that Am J Hum Genet was published by Elsevier (if only it were still at U Chicago Press), which could be a problem.

I&#39;m having second thoughts (especially in that refusing a review for this reason seems too easy...I say no to review requests almost every day), but for now I&#39;m sticking to my promise.
&lt;/blockquote&gt;

&lt;p&gt;I&amp;rsquo;m not sure whether it was the right decision.&lt;/p&gt;

&lt;p&gt;I think the most important thing for me to do is to work to get &lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt; to become open-access, or at least encourage  discussion along those lines at the &lt;a href=&#34;http://www.genetics-gsa.org&#34;&gt;Genetics Society of America&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paying for scholarly publications</title>
      <link>http://kbroman.org/blog/2012/02/02/paying-for-scholarly-publications/</link>
      <pubDate>Thu, 02 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/02/02/paying-for-scholarly-publications/</guid>
      <description>

&lt;p&gt;I have a couple of papers that I should be writing, but recent discussion (the whole PIPA/SOPA thing [see &lt;a href=&#34;http://www.eisenlab.org/eisen/&#34;&gt;Michael Eisen&amp;rsquo;s&lt;/a&gt; &lt;a href=&#34;http://www.nytimes.com/2012/01/11/opinion/research-bought-then-paid-for.html&#34;&gt;OpEd in the New York Times&lt;/a&gt;]; the &lt;a href=&#34;http://thecostofknowledge.com&#34;&gt;Elsevier boycott&lt;/a&gt;) has turned my thoughts to publishing generally.&lt;/p&gt;

&lt;p&gt;So I&amp;rsquo;ll take some time out (way &lt;em&gt;too much&lt;/em&gt; time out) to comment on the value and costs of publishing and peer review, how to pay for it, &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pmc/&#34;&gt;PubMedCentral&lt;/a&gt;, etc.
&lt;!-- more --&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-value-of-publishing&#34;&gt;The value of publishing&lt;/h3&gt;

&lt;p&gt;Obviously the most important thing is to communicate the results of research. If you don&amp;rsquo;t publish your work (in a way that it gets seen and understood), there wasn&amp;rsquo;t much point in doing it. Write, and write well.&lt;/p&gt;

&lt;p&gt;Secondly, publications are central for evaluating a researcher&amp;rsquo;s value and productivity, both for grants and promotions.&lt;/p&gt;

&lt;p&gt;In any case, broad and easy access to publications is important, particularly for the former aspect: so that other researchers (or ordinary people) can study the work.  And we don&amp;rsquo;t want to have to wait a year.&lt;/p&gt;

&lt;h3 id=&#34;the-costs-of-publishing&#34;&gt;The costs of publishing&lt;/h3&gt;

&lt;p&gt;The cost of producing a paper comes from&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Conducting the research&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Writing the paper&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Peer review (including by editors) of the paper&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Administration of the journal&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Copy editing and typesetting&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Distribution&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;how-to-pay-for-it&#34;&gt;How to pay for it&lt;/h3&gt;

&lt;p&gt;(1) and (2) are paid by research grants or institutional funds, and are definitely (most of the time) the bulk of the cost.&lt;/p&gt;

&lt;p&gt;(3) is generally provided by other researchers&amp;rsquo; volunteer services (and so are also paid, indirectly, by research grants or institutional funds).&lt;/p&gt;

&lt;p&gt;(4-6) are what the arguments are about.&lt;/p&gt;

&lt;h4 id=&#34;the-traditional-model&#34;&gt;The traditional model&lt;/h4&gt;

&lt;p&gt;Traditionally, authors signed away copyright to a publisher, who charged libraries or individual researchers for subscriptions.  Part of the cost may be covered by a fee (&amp;ldquo;page charges&amp;rdquo;) to the authors.&lt;/p&gt;

&lt;p&gt;In the distant past, the author would also purchase a bunch of paper copies of the article to give to friends or others who were interested.  I still occasionally get a postcard, mostly from overseas, asking me to send a copy of an article.  We used to get lots of those.&lt;/p&gt;

&lt;p&gt;A potential reader without access to a library with a subscription may be charged a crazy amount, like \$30, for access to a single paper.  (Cambridge University Press is apparently now &lt;a href=&#34;http://chronicle.com/blogs/wiredcampus/cambridge-u-press-would-like-to-rent-you-an-article/34500&#34;&gt;charging \$6 rent for 24 hours of access to an article&lt;/a&gt;.  Who would want that?)&lt;/p&gt;

&lt;p&gt;Many journals make articles open after a year; many charge for access for forever.&lt;/p&gt;

&lt;h4 id=&#34;the-open-access-model&#34;&gt;The open access model&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.plos.org&#34;&gt;PLoS&lt;/a&gt; and &lt;a href=&#34;http://www.biomedcentral.com&#34;&gt;BMC&lt;/a&gt; charge authors large fees (&amp;ldquo;page charges&amp;rdquo;) to publish in their journals.  Readers can then get free access.  These page charges can be pretty hefty (&lt;a href=&#34;http://www.plos.org/publish/pricing-policy/publication-fees/&#34;&gt;PLoS charges&lt;/a&gt; \$2900 for PLoS Biology, \$2250 for PLoS Genetics, and \$1350 for PLoS One.)&lt;/p&gt;

&lt;p&gt;Some pay journals have adopted an open access option.  For example, at &lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt; the standard charges are \$70/page for members of &lt;a href=&#34;http://www.genetics-gsa.org&#34;&gt;GSA&lt;/a&gt; plus \$40/figure, and you can pay an extra \$1200 to make the article open access immediately (otherwise, non-subscribers must wait a year).  For a 10 page paper with 5 figures, that would be \$900 regular and \$2100 open access.&lt;/p&gt;

&lt;p&gt;This can give you an idea of the total cost of (4-6) for a typical journal.  Imagine \$2000/paper x 20 year/issue x 12 issues/year = \$500k/year.&lt;/p&gt;

&lt;h4 id=&#34;the-sagmb-model&#34;&gt;The SAGMB model&lt;/h4&gt;

&lt;p&gt;The journal &lt;a href=&#34;http://www.degruyter.com/view/j/sagmb&#34;&gt;Statistical Applications in Genetics and Molecular Biology (SAGMB)&lt;/a&gt; had some sort of point system where you would get points for reviewing articles and you had to have so many points in order to submit (and subsequently publish) an article with them; otherwise, you paid a fee.  But the journal seems to have moved from &lt;a href=&#34;http://www.bepress.com&#34;&gt;BePress&lt;/a&gt; to &lt;a href=&#34;http://www.degruyter.com&#34;&gt;De Gruyter&lt;/a&gt; and I can no longer find the details.  And it&amp;rsquo;s definitely not an open access journal.  (And I once had a painful argument with them over a point for a review that soured me on the whole business.)&lt;/p&gt;

&lt;h4 id=&#34;endowments&#34;&gt;Endowments&lt;/h4&gt;

&lt;p&gt;My postdoc advisor, Jim Weber (now at &lt;a href=&#34;http://www.preventiongenetics.com/&#34;&gt;Prevention Genetics&lt;/a&gt;), had the idea that particularly society-related journals might raise an endowment to cover the ongoing costs of the journal, so that it could otherwise be completely free and open.  I like that idea.&lt;/p&gt;

&lt;p&gt;These days, with something like 4% return on an endowment, you&amp;rsquo;d need \$12.5 million to get \$500k/year.  That seems like a lot.  But if a journal could raise half of that, they could cut page charges in half.&lt;/p&gt;

&lt;h3 id=&#34;publishers-profit&#34;&gt;Publishers&amp;rsquo; profit&lt;/h3&gt;

&lt;p&gt;In the end, the cost for (4-6) come from research grants or other institutional funds, either indirectly (our libraries pay for subscriptions) or directly (authors pay page charges).  The main questions are how, and what cut does the publisher take?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.wikipedia.org&#34;&gt;Wikipedia&lt;/a&gt; reports that &lt;a href=&#34;http://en.wikipedia.org/wiki/Elsevier&#34;&gt;Elsevier made a profit of ~\$765 million&lt;/a&gt; in 2006.  Think of the research that might have been supported by that money.  Part of that comes from overpriced scholarly books, but still&amp;hellip;.&lt;/p&gt;

&lt;h3 id=&#34;pubmed-central&#34;&gt;PubMed Central&lt;/h3&gt;

&lt;p&gt;People seem to make a big deal about &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pmc/&#34;&gt;PubMed Central&lt;/a&gt;, like it&amp;rsquo;s been this great big thing for open access to research articles.  But I don&amp;rsquo;t see it.  I make good use of PubMed (for finding articles), but PubMed Central seems like a pain.&lt;/p&gt;

&lt;p&gt;Most of the journals I publish in send the articles straight to PMC, but the articles aren&amp;rsquo;t open until a year after publication, and there&amp;rsquo;s been no attempt to deal with the copyright release business.  And if you publish in a journal that doesn&amp;rsquo;t ship the things to PMC automatically, it&amp;rsquo;s really confusing what you need to do (a) with respect to the copyright release and (b) to actually get the appropriate version of the manuscript in there.&lt;/p&gt;

&lt;p&gt;I generally just go back to my university library website to get an article, and if I can&amp;rsquo;t get immediate access, I order it through interlibrary loan.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;http://publicaccess.nih.gov/&#34;&gt;NIH public access policy&lt;/a&gt; seems like a good thing, but it&amp;rsquo;s not enough to actually help me in any way.  They could have done more, and since they didn&amp;rsquo;t, I&amp;rsquo;m annoyed at what little they did do.&lt;/p&gt;

&lt;h3 id=&#34;what-about-peer-review-and-impact-factors-and-all-that&#34;&gt;What about peer-review and impact factors and all that?&lt;/h3&gt;

&lt;p&gt;The cost of publishing and access to research articles has gotten tied up with the whole peer-review model for publishing, plus the use of things like the ISI Impact Factor to measure the quality of a journal and then to measure the quality of the papers in a journal.  People seem to be saying, &amp;ldquo;Screw the whole page charges business; let&amp;rsquo;s just put articles in &lt;a href=&#34;http://arxiv.org&#34;&gt;arXiv&lt;/a&gt; and develop another system for finding relevant articles and measuring their quality.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;To me, the value of standard peer review versus post-publication measures of quality is a completely separate issue (which I hope to comment on more thoroughly soon).  Switching to an arXiv/tech report/working paper system just pushes the cost of (5) [copy editing] to the author (or, worse, to the reader); we still have to pay for (4) and (6) somehow.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;To summarize my thoughts: there are real costs of publishing, and in the end they all get paid for from the same pots (research grants or institutional funds).  The question is how (page charges or subscriptions or something else), and should for-profit publishers be making big bucks in the process?&lt;/p&gt;

&lt;p&gt;I personally prefer journals that are associated with a scientific society (as &lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt; is with the &lt;a href=&#34;http://www.genetics-gsa.org&#34;&gt;Genetics Society of America&lt;/a&gt;), and while I would like those societies to raise endowments to cover the full ongoing costs of their journals, in the meantime I prefer the open access model, where the publications costs are charged directly to the author and subsequently to the authors&amp;rsquo; research grants.  It&amp;rsquo;s simpler that way.&lt;/p&gt;

&lt;h3 id=&#34;how-to-change-the-world&#34;&gt;How to change the world?&lt;/h3&gt;

&lt;p&gt;I would like to see journals become fully open, with costs either charged to research grants (through page charges to the authors), directly to granting agencies, or covered by endowments. If we continue to rely on subscriptions, then there will be uneven access to researchers and little access to ordinary people.&lt;/p&gt;

&lt;p&gt;But the most important thing is to remove the profit-driven bloated middlemen from the system. The &lt;a href=&#34;http://thecostofknowledge.com&#34;&gt;Elsevier boycott&lt;/a&gt; is one step towards that: it seeks to cut out one particularly bloated but basically useless player.&lt;/p&gt;

&lt;p&gt;But researchers (particularly junior researchers) have little incentive to participate in such efforts.  They want their masterly (or crappy) manuscript to be in a high-impact journal, since its status on their CV matters more than it actually being read.  In particular, why devote their limited start-up or grant dollars towards page charges when the cost can be pushed down to the (possibly nonexistent) reader?&lt;/p&gt;

&lt;p&gt;This requires considerable thought, but here are my preliminary ideas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If senior researchers send their best manuscripts to open access journals (&lt;a href=&#34;http://www.plosbiology.org&#34;&gt;PLoS Biology&lt;/a&gt; rather than Nature; &lt;a href=&#34;http://www.plosgenetics.org&#34;&gt;PLoS Genetics&lt;/a&gt; rather than Nature Genetics), those journals will become more influential and junior researchers will follow.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Scientific societies might develop further awards or publication scholarships (or endowments!) to enable junior researchers to cover page charges (and further enhance their CVs).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If institutions care about open access, they might cut back on subscriptions to evil journals and use the savings to support researchers&amp;rsquo; page charges to open journals.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Promotion committees and such might do more to actually read candidates&amp;rsquo; papers rather than relying on journal reputation.  (Might they also take access into account?  Probably not.)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Copyright law might be changed to insist that publications coming from government-funded research be treated as are publications coming from government employees (namely, open: as I understand it, government employees aren&amp;rsquo;t allowed to sign over copyright).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Elsevier boycott</title>
      <link>http://kbroman.org/blog/2012/02/01/elsevier-boycott/</link>
      <pubDate>Wed, 01 Feb 2012 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2012/02/01/elsevier-boycott/</guid>
      <description>&lt;p&gt;I expect you&amp;rsquo;ve already heard about the &lt;a href=&#34;http://thecostofknowledge.com&#34;&gt;Elsevier boycott&lt;/a&gt;, started based on comments from &lt;a href=&#34;http://gowers.wordpress.com/2012/01/21/elsevier-my-part-in-its-downfall/&#34;&gt;Timothy Gowers&lt;/a&gt;.  While he focused on his own discipline (mathematics), the boycott site now has people broken down by subject.  On 1 Feb, there were 2700+ signatories, including 600+ mathematicians (but only 15 statisticians).  There have been a couple of articles about this in the &lt;a href=&#34;http://chronicle.com/&#34;&gt;Chronicle of Higher Education&lt;/a&gt;: &lt;a href=&#34;http://chronicle.com/blogs/wiredcampus/elsevier-publishing-boycott-gathers-steam-among-academics/35216&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://chronicle.com/article/As-Journal-Boycott-Grows/130600/?sid=wc&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I signed the boycott, and will refuse to review papers for Evilsevier journals, and will try to steer my coauthors away from them.  (I certainly wouldn&amp;rsquo;t send my own papers to such journals, but it&amp;rsquo;s hard to control papers on which I am one lowly author among many.)&lt;/p&gt;

&lt;p&gt;Most important to me is that the journals are expensive and publishing companies are reaping an enormous profit.  The former head of the library at UW-Madison mentioned recently that they spend $4 million per year on electronic resources (books and journals), and that they are &amp;ldquo;struggling to pay that Elsevier bill&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;I prefer society-related journals.  These days, my own papers all go to my favorite journal, &lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt;, which is associated with the &lt;a href=&#34;http://www.genetics-gsa.org/&#34;&gt;Genetics Society of America&lt;/a&gt;.
&lt;!-- more --&gt;&lt;/p&gt;

&lt;p&gt;I looked back at my reviews of journal articles in 2011.  I did 23.  They were for:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Various &lt;a href=&#34;http://www.biomedcentral.com&#34;&gt;BMC&lt;/a&gt; journals (open access but mostly crappy)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nature.com/ejhg/index.html&#34;&gt;European Journal of Human Genetics&lt;/a&gt; (&lt;a href=&#34;https://www.eshg.org/&#34;&gt;ESHG&lt;/a&gt;; published by Nature)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.wiley.com/bw/journal.asp?ref=1601-1848&#34;&gt;Genes, Brain and Behavior&lt;/a&gt; (&lt;a href=&#34;http://www.ibangs.org/&#34;&gt;IBANGS&lt;/a&gt;; published by Wiley)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt; (&lt;a href=&#34;http://www.genetics-gsa.org&#34;&gt;GSA&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nrcresearchpress.com/journal/gen&#34;&gt;Genome&lt;/a&gt; (&lt;a href=&#34;http://www.nrcresearchpress.com&#34;&gt;National Research Council of Canada&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://genome.cshlp.org/&#34;&gt;Genome Research&lt;/a&gt; (Cold Spring Harbor)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://jag.igr.poznan.pl/&#34;&gt;Journal of Applied Genetics&lt;/a&gt; (Springer)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Journal of Statistical Planning and Inference (Elsevier!)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.jstatsoft.org/&#34;&gt;Journal of Statistical Software&lt;/a&gt; (&lt;a href=&#34;http://www.amstat.org&#34;&gt;ASA&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nature.com/nprot/index.html&#34;&gt;Nature Protocols&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Various &lt;a href=&#34;http://www.plos.org/&#34;&gt;PLoS&lt;/a&gt; journals (open access)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I did okay.  I am down on Springer and Wiley, too, in spite of the fact that I published &lt;a href=&#34;http://www.rqtl.org/book&#34;&gt;a book with Springer&lt;/a&gt; (and I like many of their books), but most of the above are society or open-access journals and there&amp;rsquo;s just one Elsevier journal.&lt;/p&gt;

&lt;p&gt;In the list of mathematics/statistics journals published by Elsevier, I only recognize &lt;em&gt;Computational Statistics &amp;amp; Data Analysis&lt;/em&gt; and &lt;em&gt;Journal of Statistical Planning and Inference&lt;/em&gt;.  &lt;em&gt;Genomics&lt;/em&gt; and &lt;em&gt;Trends in Genetics&lt;/em&gt; are their only genetics journals that I recognize, but I didn&amp;rsquo;t look so closely.  [I later realized that the American Journal of Human Genetics is published by Elsevier; that&amp;rsquo;s a big one.]&lt;/p&gt;

&lt;p&gt;In terms of &lt;a href=&#34;http://www.biostat.wisc.edu/~kbroman/publications/&#34;&gt;my publications&lt;/a&gt;, looking at 2011, 2012 and in press articles, I have 13.  Several of the journals were listed above: &lt;a href=&#34;http://www.plos.org&#34;&gt;PLoS&lt;/a&gt;, &lt;a href=&#34;http://genome.cshlp.org/&#34;&gt;Genome Research&lt;/a&gt;, &lt;a href=&#34;http://www.biomedcentral.com&#34;&gt;BMC&lt;/a&gt;, &lt;a href=&#34;http://www.genetics.org&#34;&gt;Genetics&lt;/a&gt;/&lt;a href=&#34;http://www.g3journal.org/&#34;&gt;G3&lt;/a&gt;.  In addition:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.wiley.com/bw/journal.asp?ref=0962-1083&#34;&gt;Molecular Ecology&lt;/a&gt; (Wiley)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://neuro-oncology.oxfordjournals.org/&#34;&gt;Neuro-Oncology&lt;/a&gt; (&lt;a href=&#34;http://www.soc-neuro-onc.org/&#34;&gt;SNO&lt;/a&gt;; published by Oxford UP)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://physiolgenomics.physiology.org/&#34;&gt;Physiological Genomics&lt;/a&gt; (&lt;a href=&#34;http://www.the-aps.org/&#34;&gt;APS&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.springer.com/life+sciences/cell+biology/journal/335&#34;&gt;Mammalian Genome&lt;/a&gt; (&lt;a href=&#34;http://imgs.org&#34;&gt;IMGS&lt;/a&gt;; published by Springer)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/&#34;&gt;Bioinformatics&lt;/a&gt; (&lt;a href=&#34;http://www.iscb.org/&#34;&gt;ISCB&lt;/a&gt;; published by Oxford UP)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, again, I did okay.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fund people not projects?</title>
      <link>http://kbroman.org/blog/2011/10/19/fund-people-not-projects/</link>
      <pubDate>Wed, 19 Oct 2011 00:00:00 +0000</pubDate>
      
      <guid>http://kbroman.org/blog/2011/10/19/fund-people-not-projects/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/John_P._A._Ioannidis&#34;&gt;John Ioannidis&lt;/a&gt;, known for &lt;a href=&#34;http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020124&#34;&gt;his comments on medical research&lt;/a&gt; (see also &lt;a href=&#34;http://www.theatlantic.com/magazine/archive/2010/11/lies-damned-lies-and-medical-science/8269/&#34;&gt;the Atlantic article&lt;/a&gt;), has an interesting opinion piece in Nature on saving researchers&amp;rsquo; time writing and reviewing grants: &lt;a href=&#34;http://www.nature.com/nature/journal/v477/n7366/full/477529a.html&#34;&gt;fund people not projects&lt;/a&gt;.  As he concludes, &amp;ldquo;Requiring [scientists] to spend most of their time writing grants is irrational. It&amp;rsquo;s time to seriously consider another approach.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;It was thought provoking, but I don&amp;rsquo;t think any of his ideas will really work.  Lots of people complain about peer review, but I think it largely works well and none of the proposed alternatives would actually be better.  Here are my thoughts.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h4 id=&#34;we-pretty-much-already-do-this-in-part&#34;&gt;We pretty much already do this, in part&lt;/h4&gt;

&lt;p&gt;Prominent scientists can get sketchy ideas funded, while obscure researchers have to make an extremely strong case.  But obscure researchers with a fantastic idea &lt;em&gt;can&lt;/em&gt; get funding.&lt;/p&gt;

&lt;h4 id=&#34;spread-equally-or-at-random&#34;&gt;Spread equally or at random?&lt;/h4&gt;

&lt;p&gt;Ioannidis says, &amp;ldquo;the imperfections of peer review mean that as many as one-third of current grants are effectively being awarded at random.&amp;rdquo;  So why not use &amp;ldquo;aleatoric allocation&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d never seen the word &amp;ldquo;aleatoric&amp;rdquo; before.  I suppose now I&amp;rsquo;ll see it all the time.&lt;/p&gt;

&lt;p&gt;The idea of funding science via a lottery seems too crazy to consider further.&lt;/p&gt;

&lt;h4 id=&#34;merit&#34;&gt;Merit?&lt;/h4&gt;

&lt;p&gt;We could fund people on merit versus fund particular proposals.  Ioannidis points out that the MacArthur foundation does this.  He didn&amp;rsquo;t mention that the NIH also does this to some extent (MERIT awards, for &amp;ldquo;Method to Extend Research In Time&amp;rdquo;).&lt;/p&gt;

&lt;p&gt;Ioannidis suggests maybe doing this in an automated or semi-automated way: &amp;ldquo;The system could use indices that exclude self-citations and capture quality rather than quantity (such as average citations per paper instead of number of papers).&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Blech.&lt;/p&gt;

&lt;h4 id=&#34;reward-good-scientific-citizenship-practices&#34;&gt;&amp;ldquo;Reward good scientific citizenship practices&amp;rdquo;?&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger&lt;/a&gt; would be interested to see this comment from Ioannidis: &amp;ldquo;Researchers might be rewarded for publishing reproducible data, protocols and algorithms.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;But Ioannidis further says, &amp;ldquo;Some citizenship practices are difficult to capture in automated databases, so would be subject to the disadvantages of peer assessment.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s an understatement.&lt;/p&gt;

&lt;h4 id=&#34;simplify-application&#34;&gt;Simplify application?&lt;/h4&gt;

&lt;p&gt;&amp;ldquo;Researchers could be asked, for example, to submit short summaries of their intended research, describing broad goals only.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The NIH has moved in that direction.  But the problem is: we can all generally agree on the important problems.  The question is: who is going to solve them and how?&lt;/p&gt;

&lt;h4 id=&#34;judging-quality&#34;&gt;Judging quality&lt;/h4&gt;

&lt;p&gt;&amp;ldquo;Many institutions use the size of a scientist&amp;rsquo;s grant portfolio as a basis for tenure and promotion&amp;hellip;.Judging scientists by the size of their portfolio is equivalent to judging art by how much money was spent on paint and brushes, rather than the quality of the paintings.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Who could disagree?  Similarly, counting publications (perhaps considering the &amp;ldquo;impact factor&amp;rdquo; of the journals) is a poor measure of quality.&lt;/p&gt;

&lt;p&gt;The only alternative is to actually &lt;em&gt;read&lt;/em&gt; the papers.&lt;/p&gt;

&lt;h4 id=&#34;how-to-spread-out-the-money&#34;&gt;How to spread out the money?&lt;/h4&gt;

&lt;p&gt;&amp;ldquo;All funding options face a tension over how many scientists should receive awards, and there is no good evidence on whether it is better to give fewer scientists more money or to distribute smaller amounts between more researchers.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The NIH has indeed struggled over this.  But I think they do reasonably well.  There are some groups with a ton of funding and some that are struggling.  How to decide how much to give each?  Well, you could focus on the proposed projects rather than the researchers&amp;hellip;&lt;/p&gt;

&lt;h4 id=&#34;randomized-trials&#34;&gt;Randomized trials?&lt;/h4&gt;

&lt;p&gt;&amp;ldquo;Controlled trials could randomize consenting scientists to different funding schemes, then compare surrogate metrics and long-term successes.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s hard to see anyone really doing this.  It would require a long study and the risk of destruction of individual careers.&lt;/p&gt;

&lt;h4 id=&#34;scandal&#34;&gt;Scandal?&lt;/h4&gt;

&lt;p&gt;&amp;ldquo;It is a scandal that billions of dollars are spent on research without knowing the best way to distribute that money.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Similarly, Richard Smith wrote an interesting &lt;a href=&#34;http://breast-cancer-research.com/content/12/S4/S13&#34;&gt;opinion on peer-review&lt;/a&gt; (focusing on journal articles), in which he notes the lack of empirical evidence for the efficacy of peer review.&lt;/p&gt;

&lt;p&gt;But is it a scandal?  Do we know the best way to distribute money for anything?&lt;/p&gt;

&lt;h4 id=&#34;my-conclusions&#34;&gt;My conclusions&lt;/h4&gt;

&lt;p&gt;I would like to spend less time writing and reviewing grants, and I think the current system favors shorter, fashionable, less innovative projects.  However, while it is hard to gauge the value of proposed work, I still think it&amp;rsquo;s easier to evaluate proposed projects than it is to evaluate people.  What&amp;rsquo;s done at the NIH is a bit of a mixture (evaluating the individual investigator and their past work as well as the particular proposed project), and while I don&amp;rsquo;t always like it, I think it&amp;rsquo;s hard to improve upon.&lt;/p&gt;

&lt;p&gt;The biggest problem is the low level of current funding.  When only about 10% of proposals are funded, chance seems to play a larger role in what gets funded, and many more grants are submitted, which gives reviewers much more work.  We need to get it back up to 20% for the review process to be healthy again.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
