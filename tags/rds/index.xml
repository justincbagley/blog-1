<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rds on the stupidest thing...</title>
    <link>/tags/rds/</link>
    <description>Recent content in Rds on the stupidest thing...</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>The text in this work is licensed under CC-BY-4.0, https://creativecommons.org/licenses/by/4.0/legalcode; code licensed under the MIT License</copyright>
    <lastBuildDate>Thu, 11 May 2017 23:50:00 -0500</lastBuildDate>
    <atom:link href="/tags/rds/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>reading/writing biggish data, revisited</title>
      <link>/2017/05/11/reading/writing-biggish-data-revisited/</link>
      <pubDate>Thu, 11 May 2017 23:50:00 -0500</pubDate>
      
      <guid>/2017/05/11/reading/writing-biggish-data-revisited/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://twitter.com/mattdowle?lang=en&#34;&gt;Matt Dowle&lt;/a&gt; encouraged me to follow up on my &lt;a href=&#34;../../2017/04/30/sqlite-feather-and-fst/&#34;&gt;post about sqlite, feather, and fst&lt;/a&gt;. One thing to emphasize is that &lt;code&gt;saveRDS&lt;/code&gt;, by default, uses compression. If you use &lt;code&gt;compress=FALSE&lt;/code&gt; you can skip that and it goes &lt;em&gt;much&lt;/em&gt; faster. See, for example, &lt;a href=&#34;https://blog.h2o.ai/2016/04/fast-csv-writing-for-r/&#34;&gt;his post on “Fast csv writing for R”&lt;/a&gt;. Also see his &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki/talks/BARUG_201704_ParallelFread.pdf&#34;&gt;slides from a recent presentation on parallel fread&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll first generate the same data that I was using before. And note, as &lt;a href=&#34;https://twitter.com/shabbychef&#34;&gt;@shabbychef&lt;/a&gt; &lt;a href=&#34;https://twitter.com/shabbychef/status/858892435820130304&#34;&gt;mentioned on twitter&lt;/a&gt;, my iid simulations mean that compression isn’t likely to be useful, &lt;a href=&#34;../../2017/04/30/sqlite-feather-and-fst/&#34;&gt;as we saw in my previous post&lt;/a&gt;. So don’t assume that these results apply generally; compression is useful much of the time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_ind &amp;lt;- 500
n_snps &amp;lt;- 1e5
ind_names &amp;lt;- paste0(&amp;quot;ind&amp;quot;, 1:n_ind)
snp_names &amp;lt;- paste0(&amp;quot;snp&amp;quot;, 1:n_snps)
sigX &amp;lt;- matrix(rnorm(n_ind*n_snps), nrow=n_ind)
sigY &amp;lt;- matrix(rnorm(n_ind*n_snps), nrow=n_ind)
dimnames(sigX) &amp;lt;- list(ind_names, paste0(snp_names, &amp;quot;.X&amp;quot;))
dimnames(sigY) &amp;lt;- list(ind_names, paste0(snp_names, &amp;quot;.Y&amp;quot;))
db &amp;lt;- cbind(data.frame(id=ind_names, stringsAsFactors=FALSE),
            sigX, sigY)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s look at the time to write an RDS file, when compressed and when not. I’m again going to cache my results and just tell you what happened.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rds_file &amp;lt;- &amp;quot;db.rds&amp;quot;
saveRDS(db, rds_file, compress=FALSE)
rds_comp_file &amp;lt;- &amp;quot;db_comp.rds&amp;quot;
saveRDS(db, rds_comp_file)
db_copy1 &amp;lt;- readRDS(rds_file)
db_copy2 &amp;lt;- readRDS(rds_comp_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Writing the data to an RDS file took 5.5 sec when uncompressed and 51.4 sec when compressed. Reading them back in took 2.4 sec for the uncompressed file and 11.0 sec for the compressed file. The uncompressed RDS file was 805 MB, while the compressed one was 769 MB.&lt;/p&gt;
&lt;p&gt;So, &lt;em&gt;holy crap&lt;/em&gt; reading and writing the RDS files is fast when you use &lt;code&gt;compress=FALSE&lt;/code&gt;. Don’t tell your system administrator I said this, but if you’re working on a server with loads of disk space, for sure go with &lt;code&gt;compress=FALSE&lt;/code&gt; with your RDS files. On your laptop where uncompressed RDS files might get in the way of your music and movie libraries, you might want to use the compression.&lt;/p&gt;
&lt;div id=&#34;how-about-csv&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How about CSV?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://dirk.eddelbuettel.com/&#34;&gt;Dirk Eddelbuettel&lt;/a&gt; suggested that I might just use a plain CSV file, since &lt;code&gt;data.table::fread&lt;/code&gt; and &lt;code&gt;data.table::fwrite&lt;/code&gt; are so fast. How fast?&lt;/p&gt;
&lt;p&gt;To make use of the multi-threaded version of &lt;a href=&#34;https://github.com/Rdatatable/data.table/wiki&#34;&gt;data.table&lt;/a&gt;’s &lt;code&gt;fread&lt;/code&gt;, I need version 1.10.5 which is &lt;a href=&#34;https://github.com/rdatatable/data.table&#34;&gt;on GitHub&lt;/a&gt;. The version on &lt;a href=&#34;https://cran.r-project.org&#34;&gt;CRAN&lt;/a&gt; (&lt;a href=&#34;https://cran.r-project.org/package=data.table&#34;&gt;1.10.4&lt;/a&gt;) has multi-threaded &lt;code&gt;fwrite&lt;/code&gt; but only single-threaded &lt;code&gt;fread&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But the GitHub version needs to be compiled with OpenMP, and after a lot of screwing around to do that, I ended up getting segfaults from &lt;code&gt;fwrite&lt;/code&gt;, so I just dumped this plan.&lt;/p&gt;
&lt;p&gt;So we’ll look at multi-threaded &lt;code&gt;fwrite&lt;/code&gt; but only single-threaded &lt;code&gt;fread&lt;/code&gt;. But we can all look forward to the multi-threaded &lt;code&gt;fread&lt;/code&gt; in the near future.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;fwrite&lt;/code&gt;, the number of threads is controlled by the argument &lt;code&gt;nThread&lt;/code&gt;. The default is to call &lt;code&gt;data.table::getDTthreads()&lt;/code&gt; which detects the maximum number of cores. On my Mac desktop at work, that’s 24. I’m going to hard-code it in.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;csv_file &amp;lt;- &amp;quot;db.csv&amp;quot;
library(data.table)
fwrite(db, csv_file, quote=FALSE)
db_copy3 &amp;lt;- data.table::fread(csv_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That took 41.6 sec to write and 55.0 sec to read, and the file size is 1818 MB.&lt;/p&gt;
&lt;p&gt;How about if I set &lt;code&gt;nThread=1&lt;/code&gt; with &lt;code&gt;fwrite&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fwrite(db, csv_file, quote=FALSE, nThread=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Single-threaded, &lt;code&gt;fwrite&lt;/code&gt; took 69.1 sec.&lt;/p&gt;
&lt;p&gt;But the data set is 500 rows by 200k columns. How about if I used the transpose?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_db &amp;lt;- cbind(data.frame(snp=rep(snp_names, 2),
                         signal=rep(c(&amp;quot;X&amp;quot;, &amp;quot;Y&amp;quot;), each=n_snps),
                         stringsAsFactors=FALSE),
              rbind(t(sigX), t(sigY)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now to write and read this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;csv_t_file &amp;lt;- &amp;quot;db_t.csv&amp;quot;
fwrite(t_db, csv_t_file, quote=FALSE, nThread=24)
t_db_copy &amp;lt;- fread(csv_t_file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That took 8.3 sec to write and 26.6 sec to read, and the file size is 1818 MB.&lt;/p&gt;
&lt;p&gt;And how about if I do &lt;code&gt;fwrite&lt;/code&gt; single-threaded?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fwrite(t_db, csv_t_file, quote=FALSE, nThread=1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Single-threaded, the transposed data took 30.2 sec to write.&lt;/p&gt;
&lt;p&gt;(I’m not even going to try &lt;code&gt;read.csv&lt;/code&gt; and &lt;code&gt;write.csv&lt;/code&gt;. I’ll leave that to the reader.)&lt;/p&gt;
&lt;p&gt;Here’s a summary of the times:&lt;/p&gt;
&lt;style type=&#34;text/css&#34;&gt;.table { width: 100%; }&lt;/style&gt;
&lt;!-- html table generated in R 3.4.3 by xtable 1.8-2 package --&gt;
&lt;!-- Mon Dec 18 08:46:42 2017 --&gt;
&lt;table border=&#34;0&#34; width=&#34;100%&#34;&gt;
&lt;tr&gt;
&lt;th&gt;
function
&lt;/th&gt;
&lt;th&gt;
method
&lt;/th&gt;
&lt;th&gt;
data size
&lt;/th&gt;
&lt;th&gt;
time (s)
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
saveRDS
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
not compressed
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
5.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
saveRDS
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
compressed
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
51.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fwrite
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
24 threads
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
41.6
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fwrite
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
1 thread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
69.1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fwrite
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
24 threads
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
200k × 500
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
8.3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fwrite
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
1 thread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
200k × 500
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
30.2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
readRDS
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
not compressed
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
2.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
readRDS
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
compressed
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
200k × 500
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
11.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
1 thread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
500 × 200k
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
55.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
fread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
1 thread
&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;
200k × 500
&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;
26.6
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;For sure, &lt;code&gt;fread&lt;/code&gt; and &lt;code&gt;fwrite&lt;/code&gt; are impressive. And I’d never have thought you could get advantage from parallel reads and writes.&lt;/p&gt;
&lt;p&gt;I’m going to stick with RDS (making use of &lt;code&gt;compress=FALSE&lt;/code&gt; when I don’t care much about disk space) when I want to read/write whole files from R. And I’ll go with SQLite, feather, or fst when I want super fast access to a single row or column. But I also do a lot of reading and writing of CSV files, and I’ve enjoyed &lt;code&gt;data.table::fread&lt;/code&gt; and will now be using &lt;code&gt;data.table::fwrite&lt;/code&gt;, too.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
